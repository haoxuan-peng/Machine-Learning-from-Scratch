# Machine Learning Practice Repository

This repository contains my personal implementations of fundamental machine learning algorithms as part of my learning journey. The code demonstrates core concepts in supervised learning with practical examples.

## ğŸ“ Repository Structure

```
ML/
â”œâ”€â”€ LogisticRegression.py      # Logistic regression implementation
â”œâ”€â”€ LinearRegression.py    # Linear regression implementation
â”œâ”€â”€ comFunc.py            # Common utility functions
â”œâ”€â”€ .mplstyle             # Plotting profile
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ CL_training1.txt      # Classification dataset 1
â”œâ”€â”€ CL_training2.txt      # Classification dataset 2
â”œâ”€â”€ LR_trainingData.txt   # Linear regression training data
â””â”€â”€ LR_testData.txt       # Linear regression test data
```

## ğŸš€ Features

### Linear Regression
- **Single and multiple feature support**
- **Gradient descent optimization**
- **Feature normalization (Z-score)**
- **Cost function visualization**
- **Training vs test performance comparison**
- **Prediction visualization**

### Logistic Regression (Classification)
- **Binary classification**
- **Sigmoid activation function**
- **Gradient descent optimization**
- **Feature mapping for polynomial features**
- **Decision boundary visualization**
- **Data normalization support**
- **Training accuracy evaluation**

### Common Utilities
- **Data loading from CSV files**
- **Model output computation**
- **Visualization tools**

## ğŸ“Š Datasets

- **Linear Regression**: Population vs Profit prediction
- **Classification Dataset 1**: Exam scores for university admission
- **Classification Dataset 2**: Microchip quality control (with polynomial features)

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd ML
```

2. Create and activate virtual environment:
```bash
python -m venv venv_ML
# On Windows
venv_ML\Scripts\activate
# On macOS/Linux
source venv_ML/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

## ğŸ’» Usage

### Linear Regression
```bash
python LinearRegression.py
```

### Logistic Regression
```bash
python LogisticRegression.py
```

Both scripts will:
- Load the respective datasets
- Train models with and without normalization
- Display cost function convergence
- Show prediction visualizations
- Output training accuracy (for classification)

## ğŸ“ˆ Key Algorithms Implemented

### Gradient Descent
- Batch gradient descent optimization
- Learning rate: configurable
- Iterations: 20,000 (default)
- Cost function monitoring

### Feature Normalization
- Z-score normalization for improved convergence
- Mean centering and standard deviation scaling
- Denormalization for final parameter interpretation

### Polynomial Feature Mapping
- Up to 6th degree polynomial features
- Used for complex decision boundaries
- Implemented in Classification dataset 2

## ğŸ“‹ Dependencies

- `numpy >= 2.3.1` - Numerical computations
- `matplotlib >= 3.10.3` - Data visualization
- `contourpy >= 1.3.2` - Contour plotting support

## ğŸ¯ Learning Objectives

This repository demonstrates understanding of:

- **Supervised learning fundamentals**
- **Cost function optimization**
- **Gradient descent algorithm**
- **Feature engineering and normalization**
- **Model evaluation and visualization**
- **Overfitting prevention techniques**

## ğŸ“ Implementation Details

### Cost Functions
- **Linear Regression**: Mean Squared Error (MSE)
- **Logistic Regression**: Cross-entropy loss with regularization support

### Optimization
- **Algorithm**: Batch gradient descent
- **Learning rates**: Adaptive based on problem complexity
- **Convergence**: Cost function monitoring across iterations

### Visualization
- Training data scatter plots
- Cost function convergence curves
- Decision boundaries (classification)
- Prediction vs actual value comparisons

## ğŸ”„ Future Improvements

- [ ] Add regularization (Ridge/Lasso) for linear regression
- [ ] Implement mini-batch gradient descent
- [ ] Add cross-validation
- [ ] Support for multi-class classification
- [ ] Feature selection algorithms
- [ ] Advanced optimization algorithms (Adam, RMSprop)

## ğŸ“š Learning Resources

This implementation is based on fundamental machine learning concepts from:
- Andrew Ng's Machine Learning Course
- Pattern Recognition and Machine Learning (Bishop)
- Hands-On Machine Learning (GÃ©ron)

---

**Note**: This repo is for learning purposes and tracks my ML progress.